{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "371731306c3e504b191979706e826c247def88dc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(101)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5a0a200bfc57c5489eaa930255d9420a7d01c47",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.listdir(r'C:\\Users\\harsh\\Downloads\\Skin Cancer Detection\\input')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d24ef21f9f2359b8bf6b3e7a0b8ab5a43daaf566",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create 7 folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # nv\n",
    "    # mel\n",
    "    # bkl\n",
    "    # bcc\n",
    "    # akiec\n",
    "    # vasc\n",
    "    # df\n",
    " \n",
    "# val_dir\n",
    "    # nv\n",
    "    # mel\n",
    "    # bkl\n",
    "    # bcc\n",
    "    # akiec\n",
    "    # vasc\n",
    "    # df\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "nv = os.path.join(train_dir, 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join(train_dir, 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join(train_dir, 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join(train_dir, 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join(train_dir, 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join(train_dir, 'vasc')\n",
    "os.mkdir(vasc)\n",
    "df = os.path.join(train_dir, 'df')\n",
    "os.mkdir(df)\n",
    "\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "nv = os.path.join(val_dir, 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join(val_dir, 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join(val_dir, 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join(val_dir, 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join(val_dir, 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join(val_dir, 'vasc')\n",
    "os.mkdir(vasc)\n",
    "df = os.path.join(val_dir, 'df')\n",
    "os.mkdir(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "268503398ef61904e05a2c0b0667d589f08a19a8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(r'C:\\Users\\harsh\\Downloads\\Skin Cancer Detection\\HAM10000_metadata.csv')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24720fe3ea9f2f4b571abd09ecfbb931d6429852",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# First, count the occurrences of each lesion_id\n",
    "lesion_counts = df_data['lesion_id'].value_counts()\n",
    "\n",
    "# Define a function to check if a lesion_id has duplicates\n",
    "def identify_duplicates(x):\n",
    "    if lesion_counts[x] > 1:\n",
    "        return 'has_duplicates'\n",
    "    else:\n",
    "        return 'no_duplicates'\n",
    "\n",
    "# Apply the function to the 'lesion_id' column and store the result in a new column 'duplicates'\n",
    "df_data['duplicates'] = df_data['lesion_id'].apply(identify_duplicates)\n",
    "\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08b7eef3e0ac4112f63b8fb26ce19d55483cbc04",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_data['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "995445dfda2745165a53e61f42615104b951d4af",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# now we filter out images that don't have duplicates\n",
    "df = df_data[df_data['duplicates'] == 'no_duplicates']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39fde25b59a9452cf700c5b2ff82cc7cc45c4a33",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# now we create a val set using df because we are sure that none of these images\n",
    "# have augmented duplicates in the train set\n",
    "y = df['dx']\n",
    "\n",
    "_, df_val = train_test_split(df, test_size=0.17, random_state=101, stratify=y)\n",
    "\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1df37227f7ce993d054ed5b8480ee724696fc210",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_val['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03715a6cf5aeb6430ee144a84eb10dde216c0fb9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This set will be df_data excluding all rows that are in the val set\n",
    "\n",
    "# This function identifies if an image is part of the train\n",
    "# or val set.\n",
    "def identify_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    \n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_data['train_or_val'] = df_data['image_id']\n",
    "# apply the function to this new column\n",
    "df_data['train_or_val'] = df_data['train_or_val'].apply(identify_val_rows)\n",
    "   \n",
    "# filter out train rows\n",
    "df_train = df_data[df_data['train_or_val'] == 'train']\n",
    "\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b976a9018b1bd2dc0522c68339c5861534a1571",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1581d5a3e86f9673ae175102112017e30229bc37",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_val['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4acee2b7879762e50b52df118a9b691515fe7ac0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the image_id as the index in df_data\n",
    "df_data.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eca02fbf066c8124d0cb465295bbd2593f5f045a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get a list of images in each of the two folders\n",
    "folder_1 = os.listdir(r'C:\\Users\\harsh\\Downloads\\Skin Cancer Detection\\input\\HAM10000_images_part_1')\n",
    "folder_2 = os.listdir(r'C:\\Users\\harsh\\Downloads\\Skin Cancer Detection\\input\\HAM10000_images_part_2')\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['image_id'])\n",
    "val_list = list(df_val['image_id'])\n",
    "\n",
    "\n",
    "\n",
    "# Transfer the train images\n",
    "\n",
    "for image in train_list:\n",
    "    \n",
    "    fname = image + '.jpg'\n",
    "    label = df_data.loc[image,'dx']\n",
    "    \n",
    "    if fname in folder_1:\n",
    "        # source path to image\n",
    "        src = os.path.join(r'C:\\Users\\harsh\\Downloads\\Skin Cancer Detection\\input\\HAM10000_images_part_1', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, label, fname)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    if fname in folder_2:\n",
    "        # source path to image\n",
    "        src = os.path.join(r'C:\\Users\\harsh\\Downloads\\Skin Cancer Detection\\input\\HAM10000_images_part_2', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, label, fname)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "# Transfer the val images\n",
    "\n",
    "for image in val_list:\n",
    "    \n",
    "    fname = image + '.jpg'\n",
    "    label = df_data.loc[image,'dx']\n",
    "    \n",
    "    if fname in folder_1:\n",
    "        # source path to image\n",
    "        src = os.path.join(r'C:\\Users\\harsh\\Downloads\\Skin Cancer Detection\\input\\HAM10000_images_part_1', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, label, fname)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    if fname in folder_2:\n",
    "        # source path to image\n",
    "        src = os.path.join(r'C:\\Users\\harsh\\Downloads\\Skin Cancer Detection\\input\\HAM10000_images_part_2', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, label, fname)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a4847c4cc799c23e57bf2531d92117cb95e1b07",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check how many train images we have in each folder\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/nv')))\n",
    "print(len(os.listdir('base_dir/train_dir/mel')))\n",
    "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/train_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd05c08cbfa00418dc333f5b67d1ff6e98aa973e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check how many val images we have in each folder\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/nv')))\n",
    "print(len(os.listdir('base_dir/val_dir/mel')))\n",
    "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/val_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8fe970d74e9d5a284420af4ad37d8aae89dc1c15",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# note that we are not augmenting class 'nv'\n",
    "class_list = ['mel','bkl','bcc','akiec','vasc','df']\n",
    "\n",
    "for item in class_list:\n",
    "    \n",
    "    # We are creating temporary directories here because we delete these directories later\n",
    "    # create a base dir\n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    # create a dir within the base dir to store images of the same class\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    # Choose a class\n",
    "    img_class = item\n",
    "\n",
    "    # list all images in that directory\n",
    "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n",
    "    for fname in img_list:\n",
    "            # source path to image\n",
    "            src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
    "            # destination path to image\n",
    "            dst = os.path.join(img_dir, fname)\n",
    "            # copy the image from the source to the destination\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "    # point to a dir containing the images and not to the images themselves\n",
    "    path = aug_dir\n",
    "    save_path = 'base_dir/train_dir/' + img_class\n",
    "\n",
    "    # Create a data generator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        #brightness_range=(0.9,1.1),\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(path,\n",
    "                                           save_to_dir=save_path,\n",
    "                                           save_format='jpg',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    # Generate the augmented images and add them to the training folders\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    num_aug_images_wanted = 6000 # total number of images we want to have in each class\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
    "\n",
    "    # run the generator and create about 6000 augmented images\n",
    "    for i in range(0,num_batches):\n",
    "\n",
    "        imgs, labels = next(aug_datagen)\n",
    "        \n",
    "    # delete temporary directory with the raw image files\n",
    "    shutil.rmtree('aug_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9bbc56bd25441150d2430dca2b07d8ebae57d95",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check how many train images we now have in each folder.\n",
    "# This is the original images plus the augmented images.\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/nv')))\n",
    "print(len(os.listdir('base_dir/train_dir/mel')))\n",
    "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/train_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21de03bdc63ecf78cc061d364d14d3216a544b43",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check how many val images we have in each folder.\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/nv')))\n",
    "print(len(os.listdir('base_dir/val_dir/mel')))\n",
    "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/val_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f0e13a8455af926fe449e1b3ea818b704724202",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plots images with labels within jupyter notebook\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "        \n",
    "plots(imgs, titles=None) # titles=labels will display the image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3e2126a39c06568a1f95da2ab42353447d1be20",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# End of Data Preparation\n",
    "### ===================================================================================== ###\n",
    "# Start of Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa1041d69b0e8313324b91e3e9475799e1ad61c2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "valid_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "image_size = 224\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0e5aede7139196b0d4e1344b278e7621f005550",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "np.random.seed(101)\n",
    "tf.random.set_seed(101)\n",
    "\n",
    "# Define paths and parameters (make sure these directories exist with the right structure)\n",
    "train_path = 'base_dir/train_dir'\n",
    "valid_path = 'base_dir/val_dir'\n",
    "image_size = 224  # Image size suitable for MobileNet\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "\n",
    "# Data generator with MobileNet preprocessing\n",
    "datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "# Load training data\n",
    "train_batches = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "valid_batches = datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=val_batch_size\n",
    ")\n",
    "\n",
    "# Load test data (use shuffle=False for test set)\n",
    "test_batches = datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Display the structure of the dataset for confirmation\n",
    "print(\"Classes in training data:\", train_batches.class_indices)\n",
    "print(\"Classes in validation data:\", valid_batches.class_indices)\n",
    "print(\"Classes in test data:\", test_batches.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad582cb8ea0ca2d563fc367aa89b7edfafc1a57f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a MobileNet model with pre-trained ImageNet weights\n",
    "mobile = tf.keras.applications.MobileNet(weights='imagenet')\n",
    "\n",
    "# To create a copy of the MobileNet model, use the clone_model method\n",
    "mobile_copy = tf.keras.models.clone_model(mobile)\n",
    "\n",
    "# Optionally, copy the weights of the original model\n",
    "mobile_copy.set_weights(mobile.get_weights())\n",
    "\n",
    "# Verify by printing the model summary\n",
    "print(\"Original MobileNet model summary:\")\n",
    "mobile.summary()\n",
    "\n",
    "print(\"\\nCloned MobileNet model summary:\")\n",
    "mobile_copy.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "960449ec7ecdda92ba733ad23b00b7be605f3d4b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b7922bdf625675834d9b63ec0e85351bd9f3c0f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "type(mobile.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f832e5865c65a013a06dbf5d500c0381020c56d5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# How many layers does MobileNet have?\n",
    "len(mobile.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4dd9dcf26d85a57a113e6b158cf8fceeca7f99de",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CREATE THE MODEL ARCHITECTURE\n",
    "\n",
    "# Exclude the last 5 layers of the above model.\n",
    "# This will include all layers up to and including global_average_pooling2d_1\n",
    "x = mobile.layers[-6].output\n",
    "\n",
    "# Create a new dense layer for predictions\n",
    "# 7 corresponds to the number of classes\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "# inputs=mobile.input selects the input layer, outputs=predictions refers to the\n",
    "# dense layer we created above.\n",
    "\n",
    "model = Model(inputs=mobile.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "b38734b72afc4289ab187a9e683cbda6bf3269bc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9d74e44630c3d07a596460c8fbfda3ae7cae1e9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# We need to choose how many layers we actually want to be trained.\n",
    "\n",
    "# Here we are freezing the weights of all layers except the\n",
    "# last 23 layers in the new model.\n",
    "# The last 23 layers of the model will be trained.\n",
    "\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "915f30a4f5ad369713bcb8e3bfa438219d6c8ef7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define Top2 and Top3 Accuracy\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2013ff1abae70fed845af94e7ab3d95cefad0d61",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62e7a784a33d4c868f49a3ef1f9acbc7186e3338",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(valid_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3001857c9a3c2b15c2343627e340eb1ae858fae9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add weights to try to make the model more sensitive to melanoma\n",
    "\n",
    "class_weights={\n",
    "    0: 1.0, # akiec\n",
    "    1: 1.0, # bcc\n",
    "    2: 1.0, # bkl\n",
    "    3: 1.0, # df\n",
    "    4: 3.0, # mel # Try to make the model more sensitive to Melanoma.\n",
    "    5: 1.0, # nv\n",
    "    6: 1.0, # vasc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "4a5e3bc3cf44f1d4326c34ad880a302ba082e9d5",
    "scrolled": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Define file path for saving the model\n",
    "filepath = \"model.h5\"\n",
    "\n",
    "# ModelCheckpoint to save the best model based on validation top-3 accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "# ReduceLROnPlateau to adjust the learning rate when validation top-3 accuracy stops improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2, \n",
    "                               verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "# List of callbacks to be used during training\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "# Fit the model using the generator with the updated 'fit' method\n",
    "history = model.fit(\n",
    "    train_batches, \n",
    "    steps_per_epoch=train_steps, \n",
    "    class_weight=class_weights,\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=30, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "710ee26097924153647ac432c8ade29383fe42f1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# get the metric names so we can use evaulate_generator\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68603a5e8cb5e507db95074a07b552a61fa48e11",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "\n",
    "# Compile the model with required metrics and custom names for top-k accuracy\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', \n",
    "                       TopKCategoricalAccuracy(k=2, name='top_2_accuracy'), \n",
    "                       TopKCategoricalAccuracy(k=3, name='top_3_accuracy')])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = model.evaluate(test_batches, \n",
    "                                                                      steps=len(df_val))\n",
    "\n",
    "# Print the results\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n",
    "print('val_top_2_acc:', val_top_2_acc)\n",
    "print('val_top_3_acc:', val_top_3_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "897f066da922d81fefa165a6b911a741c52ef7f5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure you provide the correct path to the model file\n",
    "model_path = 'model.h5'  # Replace with the actual path\n",
    "\n",
    "try:\n",
    "    # Load the model weights from the specified path\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    # Evaluate the model on the test dataset\n",
    "    val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = model.evaluate_generator(\n",
    "        test_batches, steps=len(df_val)\n",
    "    )\n",
    "\n",
    "    # Print the evaluation results\n",
    "    print('val_loss:', val_loss)\n",
    "    print('val_cat_acc:', val_cat_acc)\n",
    "    print('val_top_2_acc:', val_top_2_acc)\n",
    "    print('val_top_3_acc:', val_top_3_acc)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The model file '{model_path}' was not found. Please check the file path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cbd11ef4286a751ef2918361af035d356f341ae",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_top2_acc = history.history['top_2_accuracy']\n",
    "val_top2_acc = history.history['val_top_2_accuracy']\n",
    "train_top3_acc = history.history['top_3_accuracy']\n",
    "val_top3_acc = history.history['val_top_3_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot(epochs, train_top2_acc, 'bo', label='Training top2 acc')\n",
    "plt.plot(epochs, val_top2_acc, 'b', label='Validation top2 acc')\n",
    "plt.title('Training and validation top2 accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_top3_acc, 'bo', label='Training top3 acc')\n",
    "plt.plot(epochs, val_top3_acc, 'b', label='Validation top3 acc')\n",
    "plt.title('Training and validation top3 accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74a66905f7a2d702f3d2aad9abf9fe114b96f0ff",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the labels of the test images.\n",
    "# Note that cats and dogs are in seperate folders therefore\n",
    "# the code below can get the labels depending on the folder the image is in.\n",
    "\n",
    "test_labels = test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "53f4b22617285e923f336cdb2ffcbe1f9ff5e5db",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# We need these to plot the confusion matrix.\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5113e039e8384b96595751e084f0c5ed677080a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print the label associated with each class\n",
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "701dafc5874aa60a054a74c04170cb7e8d750e94",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "predictions = model.predict_generator(test_batches, steps=len(df_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dcce17ac0488ff90d29b11592c9226ed1bb210fb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7cfd9bdbbd27e27d9c5de7c6593527686445ea89",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d499136cdb5fdf356515beb6e0cd1130ed584db",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "940b71bb2b37d847ba81dd67ca50c7fd5785fd35",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# argmax returns the index of the max value in a row\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97c6b493c368ff6565782c1bb15827f5d349ef79",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ddbd33a93468075c64ba49188a6d272a5c7828f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the labels of the class indices. These need to match the \n",
    "# order shown above.\n",
    "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c46f3f1d257241f96b4aac7eb96831ff8bbea33",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# End of Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
